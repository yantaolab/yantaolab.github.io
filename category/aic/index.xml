<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AiC | HCIC Lab</title>
    <link>https://yantaolab.github.io/category/aic/</link>
      <atom:link href="https://yantaolab.github.io/category/aic/index.xml" rel="self" type="application/rss+xml" />
    <description>AiC</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 14 May 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yantaolab.github.io/media/logo_hu7225832d305736d33d1ee86989ca8ec6_178698_300x300_fit_lanczos_3.png</url>
      <title>AiC</title>
      <link>https://yantaolab.github.io/category/aic/</link>
    </image>
    
    <item>
      <title>New publication to AiC! Learning multi-granular worker intentions from incomplete visual observations for worker-robot collaboration in construction</title>
      <link>https://yantaolab.github.io/post/11_2023_zaolin_aic/</link>
      <pubDate>Tue, 14 May 2024 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/post/11_2023_zaolin_aic/</guid>
      <description>&lt;p&gt;Recognizing a worker&amp;rsquo;s intentions is an important prerequisite to enable smooth human-robot collaboration in construction. However, the highly dynamic construction workplace and long-horizon construction tasks prevent robots from obtaining long-term observations, which is detrimental to information accumulation and intention disambiguation. We present (1) a data and knowledge fusion strategy that combines visual contextual information and task knowledge to reduce the information loss caused by incomplete observations, and (2) a multi-granularity worker intent recognition model to explore the optimal granularity by comparing the intent modeling capabilities of different granularities. Results show that the proposed method can recognize multi-granular worker intentions with macro-F1 scores higher than 0.85, and that the intermediate activity is the best-suited granularity as it strikes a good balance between intention recognition accuracy and intention modeling capability. For more details, please read our paper: &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0926580523004442&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.sciencedirect.com/science/article/pii/S0926580523004442&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Our paper &#34;Recovering Building Information Model from 2D Drawings for Mechanical, Electrical and Plumbing Systems of Ageing Buildings&#34; has been accepted by Automation in Construction!</title>
      <link>https://yantaolab.github.io/post/0429_zaolin_aic/</link>
      <pubDate>Wed, 03 May 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/post/0429_zaolin_aic/</guid>
      <description>&lt;p&gt;Ageing buildings have become a significant concern for many cities, exacerbated by inadequate management and maintenance of Mechanical, Electrical, and Plumbing (MEP) systems, and Building Information Modelling (BIM) enables efficient MEP Operation and Maintenance (O&amp;amp;M) through the digital representation of system information; however, many ageing buildings were constructed without BIM, and manual reconstruction is costly and inefficient due to the sheer number of such structures. Although some studies have proposed methods for automatically recovering BIM from 2D drawings, few are suitable for MEP systems due to the multiscale and irregular shapes of MEP components. To fill this gap, an automatic approach is proposed for recovering MEP BIM from 2D drawings with three modules: 1) semantic extraction by combining image cropping with Cascade Mask R-CNN to detect and segment multiscale, irregular MEP components; 2) geometric extraction by semantic-assisted image processing to extract contours and skeletons of irregular parts; and 3) Industry Foundation Class (IFC)-based BIM reconstruction via the open-source pythonOCC and IfcOpenShell. The performance was tested on two MEP systems with 335 and 282 multiscale and irregular elements, and the results show that the method recovered BIMs for the two MEP systems in 2.85 seconds and 0.79 seconds, with semantic extraction accuracy exceeding 0.9 and geometric error below 5%. This paper contributes to the existing body of knowledge by providing a semantic and geometric-based approach for recovering multiscale and irregular components from 2D drawings. Future studies could further improve the approach by integrating elevation drawings, reconstructing abstract symbols, and aligning text-geometry.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
