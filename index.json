
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Assistant Professor, Department of Civil and Environmental Engineering\n","date":1715644800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1715644800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Assistant Professor, Department of Civil and Environmental Engineering","tags":null,"title":"YU Yantao 于言滔","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://yantaolab.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["YU Yantao 于言滔"],"categories":["AiC",""],"content":"Construction robots have been increasingly adopted in construction projects to improve productivity, reduce risk, and speed up work cycles. Visual Simultaneous Localization and Mapping (V-SLAM) technology is widely used in construction robots due to its lightweight weight, cost-effectiveness, and provision of semantic information. On real construction sites, lighting conditions are often challenging due to factors such as uneven lighting intensity, inadequate exposure, or robots in backlit positions (e.g. roughcast houses without artificial lighting, underground car parks), which cause images captured under these conditions to exhibit low signal-to-noise ratio, uneven lighting, color distortion, noise, and other problems. These challenges make the extraction and matching of feature points in V-SLAM difficult, resulting in significant positioning errors or the inability to generate positioning trajectories for construction robotics. Although existing methods for enhancing low-light images can certainly improve image brightness, they still cannot effectively address the localization challenges brought about by low-light construction scenes with uneven illumination and noise. To address the interference of uneven and changing lighting conditions on V-SLAM localization in construction sites, this paper proposes the Unsupervised Reflectance Retinex and Noise model (URRN-Net) to enhance low-light construction images. By using a CNN model based on the Retinex theory to decompose the illumination characteristics of images, we achieve effective brightness restoration of uneven low-light images by utilizing unsupervised loss functions. URRE-Net can reduce the root mean square localization error by \u0026gt;65% compared to low-light images in the ORB-SLAM3 method, and the maximum error is reduced by \u0026gt;71% in on-site experiments. The proposed URRE-Net can be integrated with existing V-SLAM algorithms to provide more robust localization services for low-light construction site applications such as building operations (e.g., interior wall spraying robotic) or construction management tasks (e.g., automatic tunnel inspection).\n","date":1715644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715644800,"objectID":"c0fef72a3cf3789cfc5c1ad80790b734","permalink":"https://yantaolab.github.io/post/04_2024_xiniyu_aic/","publishdate":"2024-05-14T00:00:00Z","relpermalink":"/post/04_2024_xiniyu_aic/","section":"post","summary":"This paper seeks to understand worker's intentions.","tags":["AiC"],"title":"New publication to AiC! An unsupervised low-light image enhancement method for improving V-SLAM localization in uneven low-light construction sites","type":"post"},{"authors":["YU Yantao 于言滔"],"categories":["AiC",""],"content":"Recognizing a worker’s intentions is an important prerequisite to enable smooth human-robot collaboration in construction. However, the highly dynamic construction workplace and long-horizon construction tasks prevent robots from obtaining long-term observations, which is detrimental to information accumulation and intention disambiguation. We present (1) a data and knowledge fusion strategy that combines visual contextual information and task knowledge to reduce the information loss caused by incomplete observations, and (2) a multi-granularity worker intent recognition model to explore the optimal granularity by comparing the intent modeling capabilities of different granularities. Results show that the proposed method can recognize multi-granular worker intentions with macro-F1 scores higher than 0.85, and that the intermediate activity is the best-suited granularity as it strikes a good balance between intention recognition accuracy and intention modeling capability. For more details, please read our paper: https://www.sciencedirect.com/science/article/pii/S0926580523004442\n","date":1713052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713052800,"objectID":"3be894b569545731d5071a50a132eb94","permalink":"https://yantaolab.github.io/post/11_2023_zaolin_aic/","publishdate":"2024-04-14T00:00:00Z","relpermalink":"/post/11_2023_zaolin_aic/","section":"post","summary":"This paper seeks to improve V-SLAM localization in uneven low-light construction sites.","tags":["AiC"],"title":"Learning multi-granular worker intentions from incomplete visual observations for worker-robot collaboration in construction","type":"post"},{"authors":["YU Yantao 于言滔"],"categories":["AiC",""],"content":"Ageing buildings have become a significant concern for many cities, exacerbated by inadequate management and maintenance of Mechanical, Electrical, and Plumbing (MEP) systems, and Building Information Modelling (BIM) enables efficient MEP Operation and Maintenance (O\u0026amp;M) through the digital representation of system information; however, many ageing buildings were constructed without BIM, and manual reconstruction is costly and inefficient due to the sheer number of such structures. Although some studies have proposed methods for automatically recovering BIM from 2D drawings, few are suitable for MEP systems due to the multiscale and irregular shapes of MEP components. To fill this gap, an automatic approach is proposed for recovering MEP BIM from 2D drawings with three modules: 1) semantic extraction by combining image cropping with Cascade Mask R-CNN to detect and segment multiscale, irregular MEP components; 2) geometric extraction by semantic-assisted image processing to extract contours and skeletons of irregular parts; and 3) Industry Foundation Class (IFC)-based BIM reconstruction via the open-source pythonOCC and IfcOpenShell. The performance was tested on two MEP systems with 335 and 282 multiscale and irregular elements, and the results show that the method recovered BIMs for the two MEP systems in 2.85 seconds and 0.79 seconds, with semantic extraction accuracy exceeding 0.9 and geometric error below 5%. This paper contributes to the existing body of knowledge by providing a semantic and geometric-based approach for recovering multiscale and irregular components from 2D drawings. Future studies could further improve the approach by integrating elevation drawings, reconstructing abstract symbols, and aligning text-geometry.\n","date":1683072000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683936000,"objectID":"578c1a4eb9c1bb99c9b0ef3a3c43cfc3","permalink":"https://yantaolab.github.io/post/0429_zaolin_aic/","publishdate":"2023-05-03T00:00:00Z","relpermalink":"/post/0429_zaolin_aic/","section":"post","summary":"This paper aims to reconstruct IFC-based BIM from 2D MEP drawings.","tags":["AiC"],"title":"Our paper \"Recovering Building Information Model from 2D Drawings for Mechanical, Electrical and Plumbing Systems of Ageing Buildings\" has been accepted by Automation in Construction!","type":"post"},{"authors":["YU Yantao 于言滔"],"categories":["NSFC-RGC 2023",""],"content":" ","date":1683072000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683072000,"objectID":"02e70faba9ed2cbb7d3cb58c05073013","permalink":"https://yantaolab.github.io/post/nsfc-rgc2023/","publishdate":"2023-05-03T00:00:00Z","relpermalink":"/post/nsfc-rgc2023/","section":"post","summary":" ","tags":["NSFC-RGC 2023"],"title":"Our team received \"Best Paper - The Honorable mention\" award from the NSFC-RGC 2023.","type":"post"},{"authors":["Xinyu Chen","Yantao Yu"],"categories":null,"content":"","date":1676160000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676160000,"objectID":"4ad8d294a56c4c1dfbde6edd01af630e","permalink":"https://yantaolab.github.io/publication/xinyu20230212eccv/","publishdate":"2023-02-12T00:00:00Z","relpermalink":"/publication/xinyu20230212eccv/","section":"publication","summary":"Many construction scenes feature low-light work, such as nighttime construction and tunnel construction. Poor lighting and low visibility will increase the risk of site accidents. One of the leading causes of construction accidents is unsafe worker behavior, which can be predicted via worker posture estimation. Therefore, this study proposes an Unsupervised Illumination Reflectance Estimation (UIRE-Net) framework for estimating the dark worker pose. On the basis of lightness-color consistency, in spite of ungratified illumination conditions, the “true color” of objects depends on the illumination reflectance only. The illumination reflectance estimation is monotonous to neighboring pixel differences, making the extracted features robust for worker pose estimation. In addition, the proposed UIRE-Net restores image brightness without relying on image pairs. A testing experiment based on nighttime construction workers is conducted to validate the veracity.","tags":[],"title":"Image Illumination Enhancement for Construction Worker Pose Estimation in Low-light Conditions","type":"publication"},{"authors":null,"categories":null,"content":"The construction industry around the globe has unsatisfactory occupational health and safety records. One of the major reasons is attributed to high physical demands and hostile working environments. Construction work always requires workers to work for a long duration without sufficient breaks to recover from overexertion and to work under harsh climatic conditions and/or in confined workspaces. Such circumstances can increase the risk of physical fatigue. Traditionally, fatigue monitoring in the construction domain relies on self-reporting or subjective questionnaires. These methods require the manual collection of responses and are impractical for continuous fatigue monitoring. Some researchers have used on-body sensors for fatigue monitoring (such as heart rate monitors and surface electromyography (sEMG) sensors). Although these devices appear to be promising, they are intrusive, requiring sensors to be attached to the worker’s body. Such on-body sensors are uncomfortable to wear and could easily cause irritation. Considering the limitations of these methodologies, the current research proposes a novel non-intrusive method to monitor the whole-body physical fatigue with computer vision for construction workers. A computer vision-based 3D motion capture algorithm was developed to model the motion of various body parts using an RGB camera. A fatigue assessment model was developed using the 3D model data from the developed motion capture algorithm and biomechanical analysis. The experiment showed that the proposed physical fatigue assessment method could provide joint-level physical fatigue assessments automatically. Then, a series of experiments demonstrated the potential of the method in assessing the physical fatigue level of different construction task conditions such as site layout and the work-rest schedules.\n","date":1673740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673740800,"objectID":"c7bedcd482d44310be607bbc53fcf8b4","permalink":"https://yantaolab.github.io/project/fatigue/","publishdate":"2023-01-15T00:00:00Z","relpermalink":"/project/fatigue/","section":"project","summary":"A research about physical fatigue assessment for construction workers","tags":["Occupational safety and health","Ergonomic","Deep learning"],"title":"An automatic and non-invasive physical fatigue assessment method for construction workers","type":"project"},{"authors":null,"categories":null,"content":"The construction task requires high physical strength of construction workers and is easy to lead to physical fatigue of construction workers. Many construction tasks typically result in accidents and work musculoskeletal disorders (WMSD). The heavy workload will affect the safety and health of workers and will also exacerbate the labor shortage in the construction industry in many countries and regions, including Hong Kong. The exoskeleton, as a wearable external mechanical structure, may benefit workers by reducing their physical workload and improving their productivity. My research focuses on developing a biomechanical digital twin to assist the individualized design of exoskeletons for construction workers.\nThis research would apply a non-intrusive method to collect the kinematic data and establish a musculoskeletal model for construction workers. The method combines computer vision technology which is a 3D motion capture algorithm using an RGB camera and smart insoles for construction workers which is capable of monitoring the reaction force of feet generated by a work pattern. The potential, feasibility, and applicability of industrial exoskeletons applied to construction workers will be analyzed. Based on the musculoskeletal model, the biomechanical analysis will be carried out to identify exceptionally loaded positions, analyze representative muscle groups and joint loads of each pose representative of the model, find over-strained body areas and add exoskeletons. Then propose a model-based framework will be proposed to optimize and evaluate the individual exoskeleton design for construction workers. And, using the model-based approach to extend worker actions from poses to movement sequences. The research will accelerate the application of exoskeleton for construction workers.\n","date":1673740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673740800,"objectID":"828fb73508a369af6a919060dea65e88","permalink":"https://yantaolab.github.io/project/exoskeleton/","publishdate":"2023-01-15T00:00:00Z","relpermalink":"/project/exoskeleton/","section":"project","summary":"A research about occupational exoskeleton","tags":["Occupational safety and health","Occupational exoskeleton","Musculoskeletal modeling and biomechanics"],"title":"Individualized exoskeleton design for construction workers based on biomechanical digital twins","type":"project"},{"authors":null,"categories":null,"content":"Ageing buildings have become a significant concern for many cities, exacerbated by inadequate management and maintenance of Mechanical, Electrical, and Plumbing (MEP) systems, and Building Information Modelling (BIM) enables efficient MEP Operation and Maintenance (O\u0026amp;M) through the digital representation of system information; however, many ageing buildings were constructed without BIM, and manual reconstruction is costly and inefficient due to the sheer number of such structures. Although some studies have proposed methods for automatically recovering BIM from 2D drawings, few are suitable for MEP systems due to the multiscale and irregular shapes of MEP components. To fill this gap, an automatic approach is proposed for recovering MEP BIM from 2D drawings with three modules: 1) semantic extraction by combining image cropping with Cascade Mask R-CNN to detect and segment multiscale, irregular MEP components; 2) geometric extraction by semantic-assisted image processing to extract contours and skeletons of irregular parts; and 3) Industry Foundation Class (IFC)-based BIM reconstruction via the open-source pythonOCC and IfcOpenShell. The performance was tested on two MEP systems with 335 and 282 multiscale and irregular elements, and the results show that the method recovered BIMs for the two MEP systems in 2.85 seconds and 0.79 seconds, with semantic extraction accuracy exceeding 0.9 and geometric error below 5%. This paper contributes to the existing body of knowledge by providing a semantic and geometric-based approach for recovering multiscale and irregular components from 2D drawings. Future studies could further improve the approach by integrating elevation drawings, reconstructing abstract symbols, and aligning text-geometry.\n","date":1673740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673740800,"objectID":"35d444a21e144ab4234a2d133dd3b643","permalink":"https://yantaolab.github.io/project/mep2bim/","publishdate":"2023-01-15T00:00:00Z","relpermalink":"/project/mep2bim/","section":"project","summary":"A research about BIM reconstruction from 2D drawings","tags":["BIM reconstruction","Deep learning","Industry Foundation Classes (IFC)"],"title":"Recovering Building Information Model from 2D Drawings for Mechanical, Electrical and Plumbing Systems of Ageing Buildings","type":"project"},{"authors":null,"categories":null,"content":"Construction in the low-light environment is widely conducted in many construction projects, such as nighttime road construction and tunnel construction. Workers are also exposed to higher risks at low light due to dazzling lights and fatigable low-light environments. Estimating human pose can help assess workload and reduce the risk of fatigue and injury in low light. However, the existing method cannot accurately identify the Workers’ pose in the low light environment. As a result, this paper proposes an Unsupervised Illumination Reflectance Estimation Network (UIRE-Net) framework for estimating Workers’ poses in low light. The image restoration method is based on the Retinex theory, in which objects’ true color is determined solely by illumination reflectance. To begin, the Retinex method recovers the information from low-light images. The Workers’ pose estimation module is then used to track the worker’s pose. The proposed method’s pose estimation performance is evaluated using 200 low-light construction images and over 1000 Workers’ pose estimation experiments. The results show that UIRE-Net has a recognition rate of 77.9%. In the low-light construction scenario, the proposed method outperforms the baseline method by 17.8%. To improve productivity and safety performance, UIRE-Net can estimate Workers’ pose in low light and assist in completing automatic monitoring tasks in low-light construction.\n","date":1673740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673740800,"objectID":"81cd2bbcca64c18b1ec69bbd9bdb50d6","permalink":"https://yantaolab.github.io/project/lowlight/","publishdate":"2023-01-15T00:00:00Z","relpermalink":"/project/lowlight/","section":"project","summary":"A research about low light enhancement, construction workers' pose estimation, and occupational safety and health","tags":["Deep learning","Low light enhancement","Construction worker pose estimation"],"title":"Vision-based low-light construction workers' pose analysis","type":"project"},{"authors":["Maxwell Fordjour Antwi-Afari","Shahnawaz Anwer","Waleed Umer","Hao-Yang Mi","Yantao Yu","Sungkon Moon","Md. Uzzal Hossain"],"categories":null,"content":"","date":1671408000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671408000,"objectID":"09c0a6d5da24a20f6c670121aeadc8c2","permalink":"https://yantaolab.github.io/publication/maxwell20221219ijoie/","publishdate":"2022-12-19T00:00:00Z","relpermalink":"/publication/maxwell20221219ijoie/","section":"publication","summary":"Construction is known for being a labor-intensive and risky industry. Within various occupational settings such as construction, physical fatigue is an underlying health condition that may lead to musculoskeletal disorders and fall-related injuries. Identifying a worker's physical fatigue could enable safety managers to mitigate fatigue-related injuries and improve workplace operations. However, current physical fatigue assessment and identification methods include subjective, physiological, biomechanical, and computer vision approaches, which may be unreliable, intrusive, and require extensive post-processing, thus, rendering them impractical for continuous monitoring of workers' movements and automated identification of physical fatigue. Given the above, this study aims to utilize a wearable insole device to identify and classify physical fatigue levels in construction workers. Ten asymptomatic subjects were recruited to perform a fatiguing manual rebar tying activity in a laboratory setting. Borg's rating of perceived exertion (RPE) was applied as a subjective measure for collecting the levels of physical fatigue of each subject. Three sub-classification problems for identifying physical fatigue levels (i.e., PFL1, PFL2, and PFL3) were assessed. Numerous features were evaluated from the collected data samples after data segmentation. The classification performance of supervised machine learning algorithms was evaluated at a sliding window of 2.56 s. Our results from 10-fold cross-validation show an accuracy of 86% for the Random Forest (RF) algorithm, indicating the best performance among other algorithms. In addition, precision, recall, specificity, and F1-score metrics of the RF algorithm were between 52.63% and 82.62%, 52.63%–84.32%, 89.60%–92.33%, and 52.63%–83.46%, respectively. These results indicate that data samples such as acceleration and plantar pressure acquired from a wearable insole device are reliable for identifying and classifying physical fatigue levels in construction workers. In summary, this study would contribute to providing a proactive physical fatigue assessment method and guidelines for early identification of physical fatigue in construction.","tags":[],"title":"Machine learning-based identification and classification of physical fatigue levels: A novel method based on a wearable insole device","type":"publication"},{"authors":["Guohao Wang","Yantao Yu","Heng Li"],"categories":null,"content":"","date":1656460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656460800,"objectID":"16561b5d075782335aaaa11c79de3e46","permalink":"https://yantaolab.github.io/publication/guohao20220629iop/","publishdate":"2022-06-29T00:00:00Z","relpermalink":"/publication/guohao20220629iop/","section":"publication","summary":"Automatic recognition of construction workers' activities contributes to improving productivity and reducing the potential risk of injury. Kinematics sensors have been proved feasible and efficient to recognize construction activities. However, most of the sensors need to be tightly tied to workers' bodies, which might result in uncomfortableness and workers' reluctance to wear the sensors. To solve the problem, this paper proposes a less physically intrusive construction activities recognition method with a single in-pocket smartphone. The smartphone was placed in the pocket in a natural and non-fixed manner, with its built-in accelerometer and gyroscope collecting motion data. Machine learning-based classifiers were trained to recognize construction activities. An experiment simulating rebar activities was designed to verify the effectiveness of the proposed method. The experiment results showed that the proposed method could identify rebar activities (with an accuracy over 94%) in a non-intrusive manner.","tags":[],"title":"Automated activity recognition of construction workers using single in-pocket smartphone and machine learning methods","type":"publication"},{"authors":["Hongling Guo","Ying Zhou","Zaiyi Pan","Zhitian Zhang","Yantao Yu","Yan Li"],"categories":null,"content":"","date":1651190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651190400,"objectID":"5aa7f3d6650d8c9c0c33a4d420a9ce56","permalink":"https://yantaolab.github.io/publication/hongling20220429buildings/","publishdate":"2022-04-29T00:00:00Z","relpermalink":"/publication/hongling20220429buildings/","section":"publication","summary":"Accurate selection and location of mobile cranes is a critical issue on construction sites, being able to contribute to the improvement of the safety and efficiency of lifting operations. Considering the complexities and dynamics of construction sites, this study aimed to develop a useful approach for automated selection and localization of mobile cranes based on the simulation of crane operations. First, the information required for crane selection and localization is analyzed and extracted from BIM (building information modeling). Then, mainly considering the crane capacity, the initial crane type is selected with candidate location points. Based on the simulation of lifting operation at the candidate points, feasible location points and crane types are determined through three constraint checks (i.e., environment constraint, operation constraint, and safety constraint). Besides, two kinds of efficiency optimization, namely lifting time minimization and crane movement minimization, are presented to figure out the best location points from the feasible points. Finally, the proposed approach is validated using a case study. This research contributes to not only crane operation planning but also automatic construction simulation, thus supporting the implementation of intelligent construction in the future.","tags":[],"title":"Automated Selection and Localization of Mobile Cranes in Construction Planning","type":"publication"},{"authors":["Waleed Umer","Yantao Yu","Maxwell Fordjour Antwi-Afari","Li Jue","Mohsin K. Siddiqui","Heng Li"],"categories":null,"content":"","date":1650931200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650931200,"objectID":"980a92ed60802ce1325fb8e1ab11c5b0","permalink":"https://yantaolab.github.io/publication/waleed20220426ergon/","publishdate":"2022-04-26T00:00:00Z","relpermalink":"/publication/waleed20220426ergon/","section":"publication","summary":"Physical exertion monitoring has been strongly emphasized to avert the ill-effects of physically demanding nature of many industries such as construction. Recently, several sensors-based approaches have been suggested as an alternative to traditional subjective feedback-based methods. Although the proposed sensor-based approaches have laid the foundation for automated physical exertion monitoring, they require multiple on-body and/or off-body sensors to collect psychological, physiological, acceleration/posture or weather-related data. As such, multiple on-body sensors may instigate irritation and discomfort whereas other off-body sensors require additional resources for handling and managing them. To address these limitations, taking a minimalistic approach, this study explored the use of heart rate variability (HRV) metrics which could be computed from a single electrocardiogram or optical sensor (often found in fitness wrist bands and smart watches). For this purpose, manual material handling experiments were conducted while state-of-the-art HRV features were used to perform physical exertion monitoring with ensemble classifiers and artificial neural network (ANN) based regression analysis. The results indicate that ensemble classifiers achieved accuracies from 64.2% to 81.2%, depending on the number of levels in which physical exertion data was divided, whereas ANN regression achieved the least root mean square error of 1.651. Given the wide availability of HRV sensors in fitness bands and wrist watches, this study highlights the usability and limitations of HRV based physical exertion monitoring which could help make informed decisions related to its adoption in physically demanding industries such as construction.","tags":[],"title":"Heart rate variability based physical exertion monitoring for manual material handling tasks","type":"publication"},{"authors":["Waleed Umer","Yantao Yu","Maxwell Fordjour Antwi-Afari"],"categories":null,"content":"","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"8e1feda3bffe564034a758dca0590e95","permalink":"https://yantaolab.github.io/publication/waleed20220301asceco/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/publication/waleed20220301asceco/","section":"publication","summary":"Physical exertion monitoring has been strongly emphasized to avert the ill-effects of physically demanding nature of many industries such as construction. Recently, several sensors-based approaches have been suggested as an alternative to traditional subjective feedback-based methods. Although the proposed sensor-based approaches have laid the foundation for automated physical exertion monitoring, they require multiple on-body and/or off-body sensors to collect psychological, physiological, acceleration/posture or weather-related data. As such, multiple on-body sensors may instigate irritation and discomfort whereas other off-body sensors require additional resources for handling and managing them. To address these limitations, taking a minimalistic approach, this study explored the use of heart rate variability (HRV) metrics which could be computed from a single electrocardiogram or optical sensor (often found in fitness wrist bands and smart watches). For this purpose, manual material handling experiments were conducted while state-of-the-art HRV features were used to perform physical exertion monitoring with ensemble classifiers and artificial neural network (ANN) based regression analysis. The results indicate that ensemble classifiers achieved accuracies from 64.2% to 81.2%, depending on the number of levels in which physical exertion data was divided, whereas ANN regression achieved the least root mean square error of 1.651. Given the wide availability of HRV sensors in fitness bands and wrist watches, this study highlights the usability and limitations of HRV based physical exertion monitoring which could help make informed decisions related to its adoption in physically demanding industries such as construction.","tags":[],"title":"Quantifying the Effect of Mental Stress on Physical Stress for Construction Tasks","type":"publication"},{"authors":["Yantao Yu","Heng Li","Jiannong Cao","Xiaochun Luo"],"categories":null,"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"cf7a3f5a60789f50a9339b9c21a8c7ee","permalink":"https://yantaolab.github.io/publication/yantao20210201jiot/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publication/yantao20210201jiot/","section":"publication","summary":"Three-dimensional (3-D) pose data has drawn great attention owing to its wide range of applications. Internet of Things (IoT)-based techniques have been introduced to collect 3-D pose data. Though previous studies have yielded significant results, researchers have yet to use 3-D pose estimation in real-life applications. Since wearable sensors might be intrusive and infrared depth cameras are sensitive to sunlight, monocular-camera-based computer vision algorithms provide a possible solution. Previous algorithms are trained and tested with simple daily postures. There are industrial scenarios where the poses are more complex and irregular. An example is the poses of workers on construction sites, such as lifting, climbing, and rebar tying. These postures differ drastically from daily postures and vary from person to person. For instance, some workers prefer bending rebar tying, while others prefer squatting rebar tying. As a result, the previous monocular-camera-based-3-D poses estimation methods have proved to be inapplicable to industrial scenarios. Thus, this article developed a monocular-camera-based 3-D estimation method which is suitable for industry working poses. A residual artificial neural network (RANN) with flexible complexity and weighted training loss was designed. A 3-D pose data set, which consists of diversified working poses in worksites, was built to test the performance of the network in complex scenarios. Compared with previous 3-D pose capture methods, the mean per joint position error was reduced by 31.42%. The latency was 0.24 s. Thus, we conclude that the proposed monocular-camera-based method has great potential in industrial application scenarios.","tags":[],"title":"Three-Dimensional Working Pose Estimation in Industrial Scenarios With Monocular Camera","type":"publication"},{"authors":["Yantao Yu","Waleed Umer","Xincong Yang","Maxwell Fordjour Antwi-Afari"],"categories":null,"content":"","date":1611273600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611273600,"objectID":"c3b821b328712cefaffcda9a538ff1fd","permalink":"https://yantaolab.github.io/publication/yantao20210122autcon/","publishdate":"2021-01-22T00:00:00Z","relpermalink":"/publication/yantao20210122autcon/","section":"publication","summary":"Construction workers' posture-related data is closely connected with their safety, health, and productivity performance. The importance of posture-related data has drawn the attention of researchers in construction management and other fields. Accordingly, many data collection methods have been developed and applied to collect posture-related data. Despite the importance of workers' posture-related data, there lacks a review of previous data collection methods in the construction industry. This paper fills the research gap by reviewing previous methods to collect posture-related data for construction workers via 1) summarizing working principles and applications of posture-related data collection in construction management, which demonstrates the extensive use of motion sensors and Red-Green-Blue (RGB) cameras in posture-related data collection, 2) comparing the above methods based on data quality and feasibility on construction sites, which reveals the reason why motion sensors and RGB cameras have been prevalent in previous studies, 3) revealing research gaps of posture-related data collection tools and applications, and providing possible future research directions.","tags":[],"title":"Posture-related data collection methods for construction workers: A review","type":"publication"},{"authors":["Maxwell Fordjour Antwi-Afari","Heng Li","Waleed Umer","Yantao Yu","Xuejiao Xing"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"92a0a173e7be14c8424457218453b520","permalink":"https://yantaolab.github.io/publication/maxwell20200701asceco/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/publication/maxwell20200701asceco/","section":"publication","summary":"Overexertion-related construction activities are identified as a leading cause of work-related musculoskeletal disorders (WMSDs) among construction workers. However, few studies have focused on the automated recognition of overexertion-related construction workers' activities as well as assessing ergonomic risk levels, which may help to minimize WMSDs. Therefore, this study examined the feasibility of using acceleration and foot plantar pressure distribution data captured by a wearable insole pressure system for automated recognition of overexertion-related construction workers' activities and for assessing ergonomic risk levels. The proposed approach was tested by simulating overexertion-related construction activities in a laboratory setting. The classification accuracy of five types of supervised machine learning classifiers was evaluated with different window sizes to investigate classification performance and further estimate physical intensity, activity duration, and frequency information. Cross-validation results showed that the Random Forest classifier with a 2.56-s window size achieved the best classification accuracy of 98.3% and a sensitivity of more than 95.8% for each category of activities using the best features of combined data set. Furthermore, the estimation of corresponding ergonomic risk levels was within the same level of risk. The findings may help to develop a noninvasive wearable insole pressure system for the continuous monitoring and automated activity recognition, which could assist researchers and safety managers in identifying and assessing overexertion-related construction activities for minimizing the development of WMSDs' risks among construction workers. © 2020 American Society of Civil Engineers.","tags":[],"title":"Construction Activity Recognition and Ergonomic Risk Assessment Using a Wearable Insole Pressure System","type":"publication"},{"authors":["Yantao Yu","Xincong Yang","Heng Li","Xiaochun Luo","Hongling Guo","Qi Fang"],"categories":null,"content":"","date":1557014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557014400,"objectID":"aa315c396a064b478b4d2c9c2a80bb7f","permalink":"https://yantaolab.github.io/publication/yantao20190505asceco/","publishdate":"2019-05-05T00:00:00Z","relpermalink":"/publication/yantao20190505asceco/","section":"publication","summary":"Construction workers are commonly subjected to ergonomic risks. Accurate ergonomic assessment is needed to reduce ergonomic risks. However, the diverse and dynamic nature of construction sites makes it difficult to collect workers posture data for ergonomic assessment without intrusiveness. Therefore, this paper proposed a joint-level vision-based ergonomic assessment tool for construction workers (JVEC) to provide automatic and detailed ergonomic assessments of construction workers based on construction videos. JVEC extracts construction workers’ skeleton data from videos with advanced deep learning methods, then Rapid Entire Body Assessment (REBA) is used to conduct the joint-level ergonomic assessment. This approach was demonstrated and tested with a laboratory experiment and an on-site experiment, which indicated the accuracy of the ergonomic risk scores (70%–96%) and its feasibility for use on construction sites. This research contributes to an accurate and nonintrusive ergonomic assessment method for construction workers. In addition, this research for the first time introduces two-dimensional (2D) video–based three-dimensional (3D) pose estimation algorithms to the construction industry, which may benefit research on construction health, safety, and productivity by providing long-term and accurate behavior data.","tags":[],"title":"Joint-Level Vision-Based Ergonomic Assessment Tool for Construction Workers","type":"publication"},{"authors":["Yantao Yu","Heng Li","Waleed Umer","Chao Dong","Xincong Yang","Martin Skitmore","Arnold Y. L. Wong"],"categories":null,"content":"","date":1556841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556841600,"objectID":"a5395c798e4c3e5054afd4432f98d46c","permalink":"https://yantaolab.github.io/publication/yantao20190503ascecp/","publishdate":"2019-05-03T00:00:00Z","relpermalink":"/publication/yantao20190503ascecp/","section":"publication","summary":"Construction workers are commonly subject to ergonomic risks due to awkward working postures or lifting/carrying heavy objects. Accordingly, accurate ergonomic assessment is needed to help improve efficiency and reduce risks. However, the diverse and dynamic nature of construction activities makes it difficult to unobtrusively collect worker behavior data for analysis. To address this issue, an automatic workload approach is proposed for the first time to continuously assess worker body joints using image-based three-dimensional (3D) posture capture smart insoles, and biomechanical analysis to provide detailed and accurate assessments based on real data instead of simulation. This approach was tested in an experiment, indicating that the method was able to automatically collect data concerning the workers’ 3D posture, estimate external loads, and provide the estimated loads on key body joints with an error rate of 15%. In addition to helping prevent construction workers’ ergonomic risks, the method provides a new data collection approach that may benefit various behavior research fields related to construction safety and productivity management.","tags":[],"title":"Automatic Biomechanical Workload Estimation for Construction Workers by Computer Vision and Smart Insoles","type":"publication"},{"authors":["Yantao Yu","Heng Li","Xincong Yang","Liulin Kong","Xiaochun Luo","Arnold Y.L. Wong"],"categories":null,"content":"","date":1552348800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552348800,"objectID":"dd97c8345cd92706bc097c869f74520a","permalink":"https://yantaolab.github.io/publication/yantao20190312autcon/","publishdate":"2019-03-12T00:00:00Z","relpermalink":"/publication/yantao20190312autcon/","section":"publication","summary":"The construction industry around the globe has unsatisfactory occupational health and safety records. One of the major reasons is attributed to high physical demands and hostile working environments. Construction work always requires workers to work for a long duration without sufficient breaks to recover from overexertion and to work under harsh climatic conditions and/or in confined workspaces. Such circumstances can increase the risk of physical fatigue. Traditionally, fatigue monitoring in the construction domain relies on self-reporting or subjective questionnaires. These methods require the manual collection of responses and are impractical for continuous fatigue monitoring. Some researchers have used on-body sensors for fatigue monitoring (such as heart rate monitors and surface electromyography (sEMG) sensors). Although these devices appear to be promising, they are intrusive, requiring sensors to be attached to the worker's body. Such on-body sensors are uncomfortable to wear and could easily cause irritation. Considering the limitations of these methodologies, the current research proposes a novel non-intrusive method to monitor the whole-body physical fatigue with computer vision for construction workers. A computer vision-based 3D motion capture algorithm was developed to model the motion of various body parts using an RGB camera. A fatigue assessment model was developed using the 3D model data from the developed motion capture algorithm and biomechanical analysis. The experiment showed that the proposed physical fatigue assessment method could provide joint-level physical fatigue assessments automatically. Then, a series of experiments demonstrated the potential of the method in assessing the physical fatigue level of different construction task conditions such as site layout and the work-rest schedules.","tags":[],"title":"An automatic and non-invasive physical fatigue assessment method for construction workers","type":"publication"},{"authors":["Maxwell Fordjour Antwi-Afari","Heng Li","Yantao Yu","Liulin Kong"],"categories":null,"content":"","date":1539648000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539648000,"objectID":"8449cbd8e47bdf69cb206b06cc110542","permalink":"https://yantaolab.github.io/publication/maxwell20181016autcon/","publishdate":"2018-10-16T00:00:00Z","relpermalink":"/publication/maxwell20181016autcon/","section":"publication","summary":"Awkward working postures are the main risk factor for work-related musculoskeletal disorders (WMSDs) causing non-fatal occupational injuries among construction workers. However, it remains a challenge to use existing risk assessment methods for detecting and classifying awkward working postures because these methods are either intrusive or rely on subjective judgment. Therefore, this study developed a novel and non-invasive method to automatically detect and classify awkward working postures based on foot plantar pressure distribution data measured by a wearable insole pressure system. Ten asymptomatic participants performed five different types of awkward working postures (i.e., overhead working, squatting, stooping, semi-squatting, and one-legged kneeling) in a laboratory setting. Four supervised machine learning classifiers (i.e., artificial neural network (ANN), decision tree (DT), K-nearest neighbor (KNN), and support vector machine (SVM)) were used for classification performance using a 0.32 s window size. Cross-validation results showed that the SVM classifier (i.e., the best classifier) obtained a classification performance with an accuracy of 99.70% and a sensitivity of each awkward working posture was above 99.00% at 0.32 s window size. The findings substantiated that it is feasible to use a wearable insole pressure system to identify risk factors for developing WMSDs, and could help safety managers to minimize workers' exposure to awkward working postures.","tags":[],"title":"Wearable insole pressure system for automated detection and classification of awkward working postures in construction workers","type":"publication"},{"authors":["Xiaochun Luo","Heng Li","Xincong Yang","Yantao Yu","Dongping Cao"],"categories":null,"content":"","date":1538956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538956800,"objectID":"fca328611ac10679ef1cd15751440aa7","permalink":"https://yantaolab.github.io/publication/xiaocun20181008mice/","publishdate":"2018-10-08T00:00:00Z","relpermalink":"/publication/xiaocun20181008mice/","section":"publication","summary":"Recording workers’ activities is an important, but burdensome, management task for site supervisors. The last decade has seen a growing trend toward vision-based activity recognition. However, recognizing workers’ activities in far-field surveillance videos is understudied. This study proposes a hierarchical statistical method for recognizing workers’ activities in far-field surveillance videos. The method consists of two steps. First, a deep action recognition method was used to recognize workers’ actions, and a new fusion strategy was proposed to consider the characteristics of far-field surveillance videos. The deep action recognition method with the new fusion strategy has achieved the comparable performance (0.84 average accuracy) on the far-field surveillance data set in contrast to the original method on the public data sets. Second, a Bayesian nonparametric hidden semi-Markov model was innovatively used to model and infer workers’ activities based on action sequences. The latent states of the fitted Bayesian model captured workers’ activities in terms of state duration distributions and state transition distributions, which are indispensable for understanding workers’ time allocation. It has been preliminarily illustrated that the activity information learned by the Bayesian model possesses the potential to implement objective work sampling, personal physical fatigue monitoring, trade-level health risk assessment, and process-based quality control. Also, the limitations of this study are discussed.","tags":[],"title":"Capturing and Understanding Workers’ Activities in Far-Field Surveillance Videos with Deep Action Recognition and Bayesian Nonparametric Learning","type":"publication"},{"authors":["Liulin Kong","Heng Li","Yantao Yu","Hanbin Luo","Martin Skitmore","Maxwell Fordjour Antwi-Afari"],"categories":null,"content":"","date":1535673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535673600,"objectID":"0ba8db13dfd82433f2037cf74fc1a988","permalink":"https://yantaolab.github.io/publication/liulin20180831aei/","publishdate":"2018-08-31T00:00:00Z","relpermalink":"/publication/liulin20180831aei/","section":"publication","summary":"Construction workers typically undertake highly demanding physical tasks involving various types of stresses from awkward postures, using excessive force, highly repetitive actions, and excessive energy expenditure, which increases the likelihood of unsafe actions, productivity loss, and human errors. Biomechanical models have been developed to estimate joint loadings, which can help avoid strenuous physical exertion, potentially enhancing construction workforce productivity, safety, and well-being. However, the models used are mainly in 2D, or to predict static strength ignored their velocity and acceleration or using marker-based method for dynamic motion data collection. To address this issue, this paper proposes a novel framework for investigating the mechanical energy expenditure (MEE) of workers using a 3D biomechanical model based on computer vision-based techniques. Human 3D Pose Estimation algorithm based on 2D videos is applied to approximate the coordinates of human joints for working postures, and smart insoles are used to collect foot pressures and plantar accelerations, as input data for the biomechanical analyses. The results show a detailed MEE rate for the whole body, at which joints the maximum and minimum values were obtained to avoid excessive physical exertion. The proposed method can approximate the total daily MEE of construction tasks by summing the assumed cost of individual tasks (such as walking, lifting, and stooping), providing suggestions for the design of a daily workload that workers can sustain without developing cumulative fatigue.","tags":[],"title":"Quantifying the physical intensity of construction workers, a mechanical energy approach","type":"publication"},{"authors":["Xincong Yang","Heng Li","Yantao Yu","Xiaochun Luo","Dongping Cao","Ting Huang","Xu Yang"],"categories":null,"content":"","date":1535500800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535500800,"objectID":"0f7fcea83285be27c21809bcec4ed801","permalink":"https://yantaolab.github.io/publication/xincong20180829mice/","publishdate":"2018-08-29T00:00:00Z","relpermalink":"/publication/xincong20180829mice/","section":"publication","summary":"The spatial characteristics of cracks are significant indicators to assess and evaluate the health of existing buildings and infrastructures. However, the current manual crack description method is time consuming and labor consuming. To improve the efficiency of crack inspection, advanced computer vision-based techniques have been utilized to detect cracks automatically at image level and grid-cell level. But existing crack detections are of (high specificity) low generality and inefficient, in terms that conventional approaches are unable to identify and measure diverse cracks concurrently at pixel level. Therefore, this research implements a novel deep learning technique named fully convolutional network (FCN) to address this problem. First, FCN is trained by feeding multiple types of cracks to semantically identify and segment pixel-wise cracks at different scales. Then, the predicted crack segmentations are represented by single-pixel width skeletons to quantitatively measure the morphological features of cracks, providing valuable crack indicators for assessment in practice, such as crack topology, crack length, max width, and mean width. To validate the prediction, the predicted segmentations are compared with recent advanced method for crack recognition and ground truth. For crack segmentation, the accuracy, precision, recall, and F1 score are 97.96%, 81.73%, 78.97%, and 79.95%, respectively. For crack length, the relative measurement error varies from −48.03% to 177.79%, meanwhile that ranges from −13.27% to 24.01% for crack width. The results show that FCN is feasible and sufficient for crack identification and measurement. Although the accuracy is not as high as CrackNet because of three types of errors, the prediction has been increased to pixel level and the training time has been dramatically decreased to several per cents of previous methods due to the novel end-to-end structure of FCN, which combines typical convolutional neural networks and deconvolutional layers.","tags":[],"title":"Automatic Pixel-Level Crack Detection and Measurement Using Fully Convolutional Network","type":"publication"},{"authors":["Yantao Yu","Heng Li","Xincong Yang","Waleed Umer"],"categories":null,"content":"","date":1532822400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532822400,"objectID":"8dcac721055c2a5b5dd86ab40ffe9faa","permalink":"https://yantaolab.github.io/publication/yantao2018isarc/","publishdate":"2018-07-29T00:00:00Z","relpermalink":"/publication/yantao2018isarc/","section":"publication","summary":" Construction workers are commonly subjected to ergonomic risks due to awkward postures and/or excessive manual material handling. Accurate ergonomic assessment will facilitate ergonomic risk identification and the subsequent mitigation. Traditional assessment methods such as visual observation and on-body sensors rely on subjective judgement and are intrusive in nature. To cope up with the limitations of the existing technologies, a computer vision and smart insole-based joint-level ergonomic work load calculation methodology is proposed for construction workers. Accordingly, this method could provide an objective and detailed ergonomic assessment for various construction tasks. Firstly, construction workers' skeleton data is extracted using a smartphone camera with an advanced deep learning algorithm. Secondly, smart insoles are used to quantify the plantar pressures while the worker performs a construction activity. Finally, the gathered data is fed to an inverse dynamic model in order to calculate the joint torques and workloads. The aforementioned approach was tested with experiment s comprising simulations of material handling, plastering and rebar. The results reveal that the developed methodology has the potential to provide detailed and accurate ergonomic assessment. Overall, this research contributes to the knowledge of occupational safety and health in construction management by providing a novel approach to assess the risk factors of work-related musculoskeletal disorders (WMSDs). ","tags":[],"title":"Estimating Construction Workers' Physical Workload by Fusing Computer Vision and Smart Insole Technologies","type":"publication"},{"authors":["Xiaochun Luo","Heng Li","Dongping Cao","Yantao Yu","Xincong Yang","Ting Huang"],"categories":null,"content":"","date":1532476800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532476800,"objectID":"2b739b1424001385a239d346dbe52427","permalink":"https://yantaolab.github.io/publication/xiaocun20180725autcon/","publishdate":"2018-07-25T00:00:00Z","relpermalink":"/publication/xiaocun20180725autcon/","section":"publication","summary":"Capturing the working states of workers on foot allows managers to precisely quantify and benchmark labor productivity, which in turn enables them to evaluate productivity losses and identify causes. Work sampling is a widely used method for this task, while suffers from low efficiency as only one worker is selected for each observation. Attentional selection asymmetry can also bias its uniform object selection assumption. Existing vision-based methods are primarily oriented towards recognizing single, separated activities involving few workers or equipment. In this paper, we introduce an activity recognition method, which receives surveillance videos as input and produces diverse and continuous activity labels of individual workers in the field of view. Convolutional networks are used to recognize activities, which are encoded in spatial and temporal streams. A new fusion strategy is developed to combine the recognition results of the two streams. The experimental results show that our activity recognition method has achieved an average accuracy of 80.5%, which is comparable with the state-of-the-art of activity recognition in the computer vision community, given the severe camera motion and low resolution of site surveillance videos and the marginal inter-class difference and significant intra-class variation of workers' activities. We also demonstrate that our method can underpin the implementation of efficient and objective work sampling. The training and test datasets of the study are publicly available.","tags":[],"title":"Towards efficient and objective work sampling: Recognizing workers' activities in site surveillance videos with two-stream convolutional networks","type":"publication"},{"authors":["Hongling Guo","Yantao Yu","Qinghua Ding","Martin Skitmore"],"categories":null,"content":"","date":1528243200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528243200,"objectID":"962bfed6ab3c8ffe996163c050fcfa34","permalink":"https://yantaolab.github.io/publication/hongling20180606asceco/","publishdate":"2018-06-06T00:00:00Z","relpermalink":"/publication/hongling20180606asceco/","section":"publication","summary":"Workers’ unsafe behaviors are one of the main causes for construction accidents. Fully understanding the causes of unsafe behaviors on site will help to prevent them, thus reducing construction accidents. The accurate and timely identification of site workers’ unsafe behaviors can aid in the analysis of the causes of unsafe behaviors and prevention of construction accidents. However, the traditional methods (e.g.,\\ site observation) of behavior data collection on site is neither efficient nor comprehensive. This paper develops a skeleton-based real-time identification method by combining image-based technologies, construction safety knowledge, and ergonomic theory. The proposed method recognizes unsafe behaviors by simplifying dynamic motions into static postures, which can be described by a few parameters. Three basic modules are involved, an unsafe behavior database, real-time data collection module, and behavior judgement module. A laboratory test demonstrated the feasibility, efficiency, and accuracy of the method. The method has the potential to improve construction safety management by providing comprehensive data for the systematic identification of the causes to workers’ unsafe behaviors, such as inappropriate management methods, measures or decisions, personal characteristics, work space and time, as well as warning workers identified as behaving unsafely, if necessary. Thus, this paper contributes to practice and the body of knowledge of construction safety management, as well as research and practice in image-based behavior recognition. }","tags":[],"title":"Image-and-Skeleton-Based Parameterized Approach to Real-Time Identification of Construction Workers’ Unsafe Behaviors","type":"publication"},{"authors":["Qi Fang","Heng Li","Xiaochun Luo","Lieyun Ding","Timothy M. Rose","Wangpeng Ano","Yantao Yu"],"categories":null,"content":"","date":1519776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519776000,"objectID":"9dc407c88fdac13b7f8988b53ea604e7","permalink":"https://yantaolab.github.io/publication/fang20180228aei/","publishdate":"2018-02-28T00:00:00Z","relpermalink":"/publication/fang20180228aei/","section":"publication","summary":"The construction industry is a high hazard industry. Accidents frequently occur, and part of them are closely relate to workers who are not certified to carry out specific work. Although workers without a trade certificate are restricted entry to construction sites, few ad-hoc approaches have been commonly employed to check if a worker is carrying out the work for which they are certificated. This paper proposes a novel framework to check whether a site worker is working within the constraints of their certification. Our framework comprises key video clips extraction, trade recognition and worker competency evaluation. Trade recognition is a new proposed method through analyzing the dynamic spatiotemporal relevance between workers and non-worker objects. We also improved the identification results by analyzing, comparing, and matching multiple face images of each worker obtained from videos. The experimental results demonstrate the reliability and accuracy of our deep learning-based method to detect workers who are carrying out work for which they are not certified to facilitate safety inspection and supervision.","tags":[],"title":"A deep learning-based method for detecting non-certified work on construction sites","type":"publication"},{"authors":["Yantao Yu","Hongling Guo","Qinghua Ding","Heng Li","Martin Skitmore"],"categories":null,"content":"","date":1502150400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502150400,"objectID":"187be0481fcf1ae423b6d258f1ed2f67","permalink":"https://yantaolab.github.io/publication/yantao20170808autcon/","publishdate":"2017-08-08T00:00:00Z","relpermalink":"/publication/yantao20170808autcon/","section":"publication","summary":" Construction workers' unsafe behavior is one of the main reasons leading to construction accidents. However, the existing management approach to unsafe behaviors, e.g. Behavior-Based Safety (BBS), relies primarily on manual observation and recording, which not only consumes lots of time and cost but impossibly cover a whole construction site or all workers. To solve this problem and improve safety performance, an image-skeleton-based parameterized method has been proposed in a previous research to real-time identifying construction workers' unsafe behaviors. A theoretical framework has been developed with a preliminary test, but still lacking a comprehensive experiment to verify its validity, particularly in the recognition of the types of unsafe behaviors. This will have a serious impact on the extensive application of the method in real construction sites. Based on the method, this research designs and carries out a series of experiments involving three types of unsafe behaviors to examine its feasibility and accuracy, and determines the value ranges of relevant key parameters. The results of the experiment demonstrate the feasibility and efficiency of the method, being able to identify and distinguish unsafe behaviors in real time, as well as its limitations. This research not only benefits the extensive application of the method in construction safety management, but improves the effectiveness and efficiency of the method by identifying relevant future research focuses. Therefore this paper contributes to the practice as well as the body of knowledge of construction safety management. ","tags":[],"title":"An experimental study of real-time identification of construction workers' unsafe behaviors","type":"publication"},{"authors":["Hongling Guo","Yantao Yu","Tian Xiang","Heng Li","Dan Zhang"],"categories":null,"content":"","date":1497225600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497225600,"objectID":"ec74116f8416f5058aa33cfcd892176e","permalink":"https://yantaolab.github.io/publication/hongling20170612autcon/","publishdate":"2017-06-12T00:00:00Z","relpermalink":"/publication/hongling20170612autcon/","section":"publication","summary":" Construction workers' unsafe behavior is one of the main reasons leading to construction accidents. However, the existing management approach to unsafe behaviors, e.g. Behavior-Based Safety (BBS), relies primarily on manual observation and recording, which not only consumes lots of time and cost but impossibly cover a whole construction site or all workers. To solve this problem and improve safety performance, an image-skeleton-based parameterized method has been proposed in a previous research to real-time identifying construction workers' unsafe behaviors. A theoretical framework has been developed with a preliminary test, but still lacking a comprehensive experiment to verify its validity, particularly in the recognition of the types of unsafe behaviors. This will have a serious impact on the extensive application of the method in real construction sites. Based on the method, this research designs and carries out a series of experiments involving three types of unsafe behaviors to examine its feasibility and accuracy, and determines the value ranges of relevant key parameters. The results of the experiment demonstrate the feasibility and efficiency of the method, being able to identify and distinguish unsafe behaviors in real time, as well as its limitations. This research not only benefits the extensive application of the method in construction safety management, but improves the effectiveness and efficiency of the method by identifying relevant future research focuses. Therefore this paper contributes to the practice as well as the body of knowledge of construction safety management.\n","tags":[],"title":"The availability of wearable-device-based physical data for the measurement of construction workers' psychological status on site: From the perspective of safety management","type":"publication"},{"authors":["Hongling Guo","Yantao Yu","Martin Skitmore"],"categories":null,"content":"","date":1480377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480377600,"objectID":"e94b371d186576e570e6cbab190f5a11","permalink":"https://yantaolab.github.io/publication/hongling20161129autcon/","publishdate":"2016-11-29T00:00:00Z","relpermalink":"/publication/hongling20161129autcon/","section":"publication","summary":" Construction safety management has been a popular issue in research and practice in recent years due to the high accident and death rates in the construction industry. The complexity and variability of construction sites makes safety management more difficult to implement than in other industries. As a promising technology, visualization has been extensively explored to aid construction safety management. However, a comprehensive critical review of the visualization technology in construction safety management is absent in the literature.\nThis paper provides a comprehensive review to investigate research and development, application methods, achievements and barriers to the use of visualization technology in safety management, and suggests possible future research directions to extend its application. It is found that visualization technology can improve safety management by aiding safety training, job hazard area (JHA) identification and on-site safety monitoring and warnings, but there are barriers or limitations involved. Existing location technologies, for instance, can perform well only in relatively small areas due to their generally poor penetrating performance. Finally, possible future research directions are proposed to benefit the extensive application of visualization technology for construction safety management in both theory and practice. ","tags":[],"title":" Visualization technology-based construction safety management: A review ","type":"publication"}]