<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HCIC Lab</title>
    <link>https://yantaolab.github.io/</link>
      <atom:link href="https://yantaolab.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>HCIC Lab</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yantaolab.github.io/media/logo_hu7225832d305736d33d1ee86989ca8ec6_178698_300x300_fit_lanczos_3.png</url>
      <title>HCIC Lab</title>
      <link>https://yantaolab.github.io/</link>
    </image>
    
    <item>
      <title>Example Talk</title>
      <link>https://yantaolab.github.io/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Our team won the Second Prize (Mathematics and Physics / Mechanical and Control Systems Category) in the 10th Hong Kong University Student Innovation and Entrepreneurship Competition.</title>
      <link>https://yantaolab.github.io/post/hkchallenge2024/</link>
      <pubDate>Wed, 12 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/post/hkchallenge2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New publication to AiC! An unsupervised low-light image enhancement method for improving V-SLAM localization in uneven low-light construction sites</title>
      <link>https://yantaolab.github.io/post/04_2024_xiniyu_aic/</link>
      <pubDate>Tue, 14 May 2024 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/post/04_2024_xiniyu_aic/</guid>
      <description>&lt;p&gt;Construction robots have been increasingly adopted in construction projects to improve productivity, reduce risk, and speed up work cycles. Visual Simultaneous Localization and Mapping (V-SLAM) technology is widely used in construction robots due to its lightweight weight, cost-effectiveness, and provision of semantic information. On real construction sites, lighting conditions are often challenging due to factors such as uneven lighting intensity, inadequate exposure, or robots in backlit positions (e.g. roughcast houses without artificial lighting, underground car parks), which cause images captured under these conditions to exhibit low signal-to-noise ratio, uneven lighting, color distortion, noise, and other problems. These challenges make the extraction and matching of feature points in V-SLAM difficult, resulting in significant positioning errors or the inability to generate positioning trajectories for construction robotics. Although existing methods for enhancing low-light images can certainly improve image brightness, they still cannot effectively address the localization challenges brought about by low-light construction scenes with uneven illumination and noise. To address the interference of uneven and changing lighting conditions on V-SLAM localization in construction sites, this paper proposes the Unsupervised Reflectance Retinex and Noise model (URRN-Net) to enhance low-light construction images. By using a CNN model based on the Retinex theory to decompose the illumination characteristics of images, we achieve effective brightness restoration of uneven low-light images by utilizing unsupervised loss functions. URRE-Net can reduce the root mean square localization error by &amp;gt;65% compared to low-light images in the ORB-SLAM3 method, and the maximum error is reduced by &amp;gt;71% in on-site experiments. The proposed URRE-Net can be integrated with existing V-SLAM algorithms to provide more robust localization services for low-light construction site applications such as building operations (e.g., interior wall spraying robotic) or construction management tasks (e.g., automatic tunnel inspection).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Estimation of load-carrying capacity of cracked RC beams using 3D digital twin model integrated with point clouds and images</title>
      <link>https://yantaolab.github.io/publication/congguang20240503es/</link>
      <pubDate>Fri, 03 May 2024 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/congguang20240503es/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning multi-granular worker intentions from incomplete visual observations for worker-robot collaboration in construction</title>
      <link>https://yantaolab.github.io/post/intention/</link>
      <pubDate>Sun, 14 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/post/intention/</guid>
      <description>&lt;p&gt;Recognizing a worker&amp;rsquo;s intentions is an important prerequisite to enable smooth human-robot collaboration in construction. However, the highly dynamic construction workplace and long-horizon construction tasks prevent robots from obtaining long-term observations, which is detrimental to information accumulation and intention disambiguation. We present (1) a data and knowledge fusion strategy that combines visual contextual information and task knowledge to reduce the information loss caused by incomplete observations, and (2) a multi-granularity worker intent recognition model to explore the optimal granularity by comparing the intent modeling capabilities of different granularities. Results show that the proposed method can recognize multi-granular worker intentions with macro-F1 scores higher than 0.85, and that the intermediate activity is the best-suited granularity as it strikes a good balance between intention recognition accuracy and intention modeling capability. For more details, please read our paper: &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0926580523004442&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.sciencedirect.com/science/article/pii/S0926580523004442&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fatigue in construction workers: A systematic review of causes, evaluation methods, and interventions</title>
      <link>https://yantaolab.github.io/publication/haiyi20230410safety/</link>
      <pubDate>Wed, 10 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/haiyi20230410safety/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SLAM localization in uneven low-light construction sites</title>
      <link>https://yantaolab.github.io/publication/xinyu20240403aic/</link>
      <pubDate>Wed, 03 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/xinyu20240403aic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Design information-assisted graph neural network for modeling central air conditioning systems</title>
      <link>https://yantaolab.github.io/publication/ao20240131aei/</link>
      <pubDate>Wed, 31 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/ao20240131aei/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Measuring Labor Input: Construction Activity Counting Using IMU on Hand Tools</title>
      <link>https://yantaolab.github.io/publication/xincong202031122sensor/</link>
      <pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/xincong202031122sensor/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning multi-granular worker intentions from incomplete visual observations for worker-robot collaboration in construction</title>
      <link>https://yantaolab.github.io/publication/zaolin20231102aic/</link>
      <pubDate>Thu, 02 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/zaolin20231102aic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HLE-SLAM: SLAM for overexposed construction environment</title>
      <link>https://yantaolab.github.io/publication/xinyu20230707isarc/</link>
      <pubDate>Fri, 07 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/xinyu20230707isarc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Low-light Image Enhancement for Construction Robot Simultaneous Localization and Mapping</title>
      <link>https://yantaolab.github.io/publication/xinyu20230706isarc/</link>
      <pubDate>Thu, 06 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/xinyu20230706isarc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning Multi-Granularity Task Primitives from Construction Videos for Human-Robot Collaboration</title>
      <link>https://yantaolab.github.io/publication/zaolin20230429i3ce/</link>
      <pubDate>Sun, 25 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/zaolin20230429i3ce/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards automated physical fatigue monitoring and prediction among construction workers using physiological signals: An on-site study</title>
      <link>https://yantaolab.github.io/publication/waleed20230607safety/</link>
      <pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/waleed20230607safety/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recovering building information model from 2D drawings for mechanical, electrical and plumbing systems of ageing buildings</title>
      <link>https://yantaolab.github.io/publication/zaolin20230513aic/</link>
      <pubDate>Sat, 13 May 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/zaolin20230513aic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Identification and Classification of Physical Fatigue in Construction Workers Using Linear and Nonlinear Heart Rate Variability Measurements</title>
      <link>https://yantaolab.github.io/publication/shahnawaz20230512asceco/</link>
      <pubDate>Fri, 12 May 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/shahnawaz20230512asceco/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Recovering Building Information Model from 2D Drawings for Mechanical, Electrical and Plumbing Systems of Ageing Buildings&#34; has been accepted by Automation in Construction!</title>
      <link>https://yantaolab.github.io/post/0429_zaolin_aic/</link>
      <pubDate>Wed, 03 May 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/post/0429_zaolin_aic/</guid>
      <description>&lt;p&gt;Ageing buildings have become a significant concern for many cities, exacerbated by inadequate management and maintenance of Mechanical, Electrical, and Plumbing (MEP) systems, and Building Information Modelling (BIM) enables efficient MEP Operation and Maintenance (O&amp;amp;M) through the digital representation of system information; however, many ageing buildings were constructed without BIM, and manual reconstruction is costly and inefficient due to the sheer number of such structures. Although some studies have proposed methods for automatically recovering BIM from 2D drawings, few are suitable for MEP systems due to the multiscale and irregular shapes of MEP components. To fill this gap, an automatic approach is proposed for recovering MEP BIM from 2D drawings with three modules: 1) semantic extraction by combining image cropping with Cascade Mask R-CNN to detect and segment multiscale, irregular MEP components; 2) geometric extraction by semantic-assisted image processing to extract contours and skeletons of irregular parts; and 3) Industry Foundation Class (IFC)-based BIM reconstruction via the open-source pythonOCC and IfcOpenShell. The performance was tested on two MEP systems with 335 and 282 multiscale and irregular elements, and the results show that the method recovered BIMs for the two MEP systems in 2.85 seconds and 0.79 seconds, with semantic extraction accuracy exceeding 0.9 and geometric error below 5%. This paper contributes to the existing body of knowledge by providing a semantic and geometric-based approach for recovering multiscale and irregular components from 2D drawings. Future studies could further improve the approach by integrating elevation drawings, reconstructing abstract symbols, and aligning text-geometry.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Our team received &#34;Best Paper - The Honorable mention&#34; award from the NSFC-RGC 2023.</title>
      <link>https://yantaolab.github.io/post/nsfc-rgc2023/</link>
      <pubDate>Wed, 03 May 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/post/nsfc-rgc2023/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://yantaolab.github.io/img/post/featured1.jpg&#34; alt=&#34;pic&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computer vision–based management of construction workers unsafe behaviour</title>
      <link>https://yantaolab.github.io/publication/hongling20230228buildings/</link>
      <pubDate>Tue, 28 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/hongling20230228buildings/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image Illumination Enhancement for Construction Worker Pose Estimation in Low-light Conditions</title>
      <link>https://yantaolab.github.io/publication/xinyu20230212eccv/</link>
      <pubDate>Sun, 12 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/xinyu20230212eccv/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An automatic and non-invasive physical fatigue assessment method for construction workers</title>
      <link>https://yantaolab.github.io/project/fatigue/</link>
      <pubDate>Sun, 15 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/project/fatigue/</guid>
      <description>&lt;p&gt;The construction industry around the globe has unsatisfactory occupational health and safety records. One of the major reasons is attributed to high physical demands and hostile working environments. Construction work always requires workers to work for a long duration without sufficient breaks to recover from overexertion and to work under harsh climatic conditions and/or in confined workspaces. Such circumstances can increase the risk of physical fatigue. Traditionally, fatigue monitoring in the construction domain relies on self-reporting or subjective questionnaires. These methods require the manual collection of responses and are impractical for continuous fatigue monitoring. Some researchers have used on-body sensors for fatigue monitoring (such as heart rate monitors and surface electromyography (sEMG) sensors). Although these devices appear to be promising, they are intrusive, requiring sensors to be attached to the worker&amp;rsquo;s body. Such on-body sensors are uncomfortable to wear and could easily cause irritation. Considering the limitations of these methodologies, the current research proposes a novel non-intrusive method to monitor the whole-body physical fatigue with computer vision for construction workers. A computer vision-based 3D motion capture algorithm was developed to model the motion of various body parts using an RGB camera. A fatigue assessment model was developed using the 3D model data from the developed motion capture algorithm and biomechanical analysis. The experiment showed that the proposed physical fatigue assessment method could provide joint-level physical fatigue assessments automatically. Then, a series of experiments demonstrated the potential of the method in assessing the physical fatigue level of different construction task conditions such as site layout and the work-rest schedules.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Individualized exoskeleton design for construction workers based on biomechanical digital twins</title>
      <link>https://yantaolab.github.io/project/exoskeleton/</link>
      <pubDate>Sun, 15 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/project/exoskeleton/</guid>
      <description>&lt;p&gt;The construction task requires high physical strength of construction workers and is easy to lead to physical fatigue of construction workers. Many construction tasks typically result in accidents and work musculoskeletal disorders (WMSD). The heavy workload will affect the safety and health of workers and will also exacerbate the labor shortage in the construction industry in many countries and regions, including Hong Kong. The exoskeleton, as a wearable external mechanical structure, may benefit workers by reducing their physical workload and improving their productivity. My research focuses on developing a biomechanical digital twin to assist the individualized design of exoskeletons for construction workers.&lt;/p&gt;
&lt;p&gt;This research would apply a non-intrusive method to collect the kinematic data and establish a musculoskeletal model for construction workers. The method combines computer vision technology which is a 3D motion capture algorithm using an RGB camera and smart insoles for construction workers which is capable of monitoring the reaction force of feet generated by a work pattern. The potential, feasibility, and applicability of industrial exoskeletons applied to construction workers will be analyzed. Based on the musculoskeletal model, the biomechanical analysis will be carried out to identify exceptionally loaded positions, analyze representative muscle groups and joint loads of each pose representative of the model, find over-strained body areas and add exoskeletons. Then propose a model-based framework will be proposed to optimize and evaluate the individual exoskeleton design for construction workers. And, using the model-based approach to extend worker actions from poses to movement sequences. The research will accelerate the application of exoskeleton for construction workers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Recovering Building Information Model from 2D Drawings for Mechanical, Electrical and Plumbing Systems of Ageing Buildings</title>
      <link>https://yantaolab.github.io/project/mep2bim/</link>
      <pubDate>Sun, 15 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/project/mep2bim/</guid>
      <description>&lt;p&gt;Ageing buildings have become a significant concern for many cities, exacerbated by inadequate management and maintenance of Mechanical, Electrical, and Plumbing (MEP) systems, and Building Information Modelling (BIM) enables efficient MEP Operation and Maintenance (O&amp;amp;M) through the digital representation of system information; however, many ageing buildings were constructed without BIM, and manual reconstruction is costly and inefficient due to the sheer number of such structures. Although some studies have proposed methods for automatically recovering BIM from 2D drawings, few are suitable for MEP systems due to the multiscale and irregular shapes of MEP components. To fill this gap, an automatic approach is proposed for recovering MEP BIM from 2D drawings with three modules: 1) semantic extraction by combining image cropping with Cascade Mask R-CNN to detect and segment multiscale, irregular MEP components; 2) geometric extraction by semantic-assisted image processing to extract contours and skeletons of irregular parts; and 3) Industry Foundation Class (IFC)-based BIM reconstruction via the open-source pythonOCC and IfcOpenShell. The performance was tested on two MEP systems with 335 and 282 multiscale and irregular elements, and the results show that the method recovered BIMs for the two MEP systems in 2.85 seconds and 0.79 seconds, with semantic extraction accuracy exceeding 0.9 and geometric error below 5%. This paper contributes to the existing body of knowledge by providing a semantic and geometric-based approach for recovering multiscale and irregular components from 2D drawings. Future studies could further improve the approach by integrating elevation drawings, reconstructing abstract symbols, and aligning text-geometry.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vision-based low-light construction workers&#39; pose analysis</title>
      <link>https://yantaolab.github.io/project/lowlight/</link>
      <pubDate>Sun, 15 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/project/lowlight/</guid>
      <description>&lt;p&gt;Construction in the low-light environment is widely conducted in many construction projects, such as nighttime road construction and tunnel construction. Workers are also exposed to higher risks at low light due to dazzling lights and fatigable low-light environments. Estimating human pose can help assess workload and reduce the risk of fatigue and injury in low light. However, the existing method cannot accurately identify the Workers&amp;rsquo; pose in the low light environment. As a result, this paper proposes an Unsupervised Illumination Reflectance Estimation Network (UIRE-Net) framework for estimating Workers&amp;rsquo; poses in low light. The image restoration method is based on the Retinex theory, in which objects&amp;rsquo; true color is determined solely by illumination reflectance. To begin, the Retinex method recovers the information from low-light images. The Workers&amp;rsquo; pose estimation module is then used to track the worker&amp;rsquo;s pose. The proposed method&amp;rsquo;s pose estimation performance is evaluated using 200 low-light construction images and over 1000 Workers&amp;rsquo; pose estimation experiments. The results show that UIRE-Net has a recognition rate of 77.9%. In the low-light construction scenario, the proposed method outperforms the baseline method by 17.8%. To improve productivity and safety performance, UIRE-Net can estimate Workers&amp;rsquo; pose in low light and assist in completing automatic monitoring tasks in low-light construction.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine learning-based identification and classification of physical fatigue levels: A novel method based on a wearable insole device</title>
      <link>https://yantaolab.github.io/publication/maxwell20221219ijoie/</link>
      <pubDate>Mon, 19 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/maxwell20221219ijoie/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Automated activity recognition of construction workers using single in-pocket smartphone and machine learning methods</title>
      <link>https://yantaolab.github.io/publication/guohao20220629iop/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/guohao20220629iop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Automated Selection and Localization of Mobile Cranes in Construction Planning</title>
      <link>https://yantaolab.github.io/publication/hongling20220429buildings/</link>
      <pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/hongling20220429buildings/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Heart rate variability based physical exertion monitoring for manual material handling tasks</title>
      <link>https://yantaolab.github.io/publication/waleed20220426ergon/</link>
      <pubDate>Tue, 26 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/waleed20220426ergon/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quantifying the Effect of Mental Stress on Physical Stress for Construction Tasks</title>
      <link>https://yantaolab.github.io/publication/waleed20220301asceco/</link>
      <pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/waleed20220301asceco/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Three-Dimensional Working Pose Estimation in Industrial Scenarios With Monocular Camera</title>
      <link>https://yantaolab.github.io/publication/yantao20210201jiot/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/yantao20210201jiot/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Posture-related data collection methods for construction workers: A review</title>
      <link>https://yantaolab.github.io/publication/yantao20210122autcon/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/yantao20210122autcon/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Construction Activity Recognition and Ergonomic Risk Assessment Using a Wearable Insole Pressure System</title>
      <link>https://yantaolab.github.io/publication/maxwell20200701asceco/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/maxwell20200701asceco/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Joint-Level Vision-Based Ergonomic Assessment Tool for Construction Workers</title>
      <link>https://yantaolab.github.io/publication/yantao20190505asceco/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/yantao20190505asceco/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Automatic Biomechanical Workload Estimation for Construction Workers by Computer Vision and Smart Insoles</title>
      <link>https://yantaolab.github.io/publication/yantao20190503ascecp/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/yantao20190503ascecp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An automatic and non-invasive physical fatigue assessment method for construction workers</title>
      <link>https://yantaolab.github.io/publication/yantao20190312autcon/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/yantao20190312autcon/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Wearable insole pressure system for automated detection and classification of awkward working postures in construction workers</title>
      <link>https://yantaolab.github.io/publication/maxwell20181016autcon/</link>
      <pubDate>Tue, 16 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/maxwell20181016autcon/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Capturing and Understanding Workers’ Activities in Far-Field Surveillance Videos with Deep Action Recognition and Bayesian Nonparametric Learning</title>
      <link>https://yantaolab.github.io/publication/xiaocun20181008mice/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/xiaocun20181008mice/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quantifying the physical intensity of construction workers, a mechanical energy approach</title>
      <link>https://yantaolab.github.io/publication/liulin20180831aei/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/liulin20180831aei/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Automatic Pixel-Level Crack Detection and Measurement Using Fully Convolutional Network</title>
      <link>https://yantaolab.github.io/publication/xincong20180829mice/</link>
      <pubDate>Wed, 29 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/xincong20180829mice/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Estimating Construction Workers&#39; Physical Workload by Fusing Computer Vision and Smart Insole Technologies</title>
      <link>https://yantaolab.github.io/publication/yantao2018isarc/</link>
      <pubDate>Sun, 29 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/yantao2018isarc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards efficient and objective work sampling: Recognizing workers&#39; activities in site surveillance videos with two-stream convolutional networks</title>
      <link>https://yantaolab.github.io/publication/xiaocun20180725autcon/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/xiaocun20180725autcon/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image-and-Skeleton-Based Parameterized Approach to Real-Time Identification of Construction Workers’ Unsafe Behaviors</title>
      <link>https://yantaolab.github.io/publication/hongling20180606asceco/</link>
      <pubDate>Wed, 06 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/hongling20180606asceco/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A deep learning-based method for detecting non-certified work on construction sites</title>
      <link>https://yantaolab.github.io/publication/fang20180228aei/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/fang20180228aei/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An experimental study of real-time identification of construction workers&#39; unsafe behaviors</title>
      <link>https://yantaolab.github.io/publication/yantao20170808autcon/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/yantao20170808autcon/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The availability of wearable-device-based physical data for the measurement of construction workers&#39; psychological status on site: From the perspective of safety management</title>
      <link>https://yantaolab.github.io/publication/hongling20170612autcon/</link>
      <pubDate>Mon, 12 Jun 2017 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/hongling20170612autcon/</guid>
      <description></description>
    </item>
    
    <item>
      <title> Visualization technology-based construction safety management: A review </title>
      <link>https://yantaolab.github.io/publication/hongling20161129autcon/</link>
      <pubDate>Tue, 29 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/publication/hongling20161129autcon/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://yantaolab.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://yantaolab.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
